{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Davidon Fletcher Powell Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy.optimize as sopt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcx(x):\n",
    "    fx = 100*(np.sqrt(x[0]**2+(x[1]+1)**2)-1)**2 + 90*(np.sqrt(x[0]**2+(x[1]+1)**2)-1)**2 -(20*x[0]+40*x[1])\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x,delta):\n",
    "    grad=np.zeros(2)\n",
    "    grad[0]=(funcx([x[0]+delta,x[1]])- funcx([x[0]-delta,x[1]]))/(2*delta)\n",
    "    grad[1]=(funcx([x[0],x[1]+delta])- funcx([x[0],x[1]-delta]))/(2*delta)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def golden(x,search,xi,eps):\n",
    "    a = xi[0];\n",
    "    b = xi[1];\n",
    "    tau = 0.381967;\n",
    "    alpha1 = a*(1-tau) + b*tau;\n",
    "    alpha2 = a*tau + b*(1-tau);\n",
    "    falpha1 = funcx(x+alpha1*search);\n",
    "    falpha2 = funcx(x+alpha2*search);\n",
    "    for i in range(100):\n",
    "        if falpha1 > falpha2:\n",
    "            a = alpha1;\n",
    "            alpha1 = alpha2;\n",
    "            falpha1 = falpha2;\n",
    "            alpha2 = tau*a + (1-tau)*b;\n",
    "            falpha2 = funcx(x+alpha2*search);\n",
    "        else:\n",
    "            b = alpha2;\n",
    "            alpha2 = alpha1;\n",
    "            falpha2 = falpha1;\n",
    "            alpha1 = tau*b + (1-tau)*a;\n",
    "            falpha1 = funcx(x+alpha1*search);\n",
    "\n",
    "        if np.abs(funcx(x+alpha1*search)- funcx(x+alpha2*search)) < eps :\n",
    "            break;\n",
    "    return alpha1,falpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(x,delta):\n",
    "    H=np.zeros([2,2])\n",
    "    H[0,0]= ( funcx([x[0]+delta,x[1]])  - 2*funcx(x) + funcx([x[0]-delta,x[1]]) )/ delta**2;\n",
    "    H[1,1]= ( funcx([x[0],x[1]+delta])  - 2*funcx(x) + funcx([x[0],x[1]-delta]) )/ delta**2; \n",
    "    H[0,1]= ( funcx([x[0]+delta,x[1]+delta]) - funcx([x[0]+delta,x[1]-delta]) - funcx([x[0]-delta,x[1]+delta]) + funcx([x[0]-delta,x[1]-delta]) )/ (4*(delta**2));\n",
    "    H[1,0]=H[0,1]\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial function value = 270.294 \n",
      " No.\tx-vector\tf(x)\tDeriv \n",
      "------------------------------------------\n",
      "0\t[-1.000,1.000]\t-7.352\t0.451\n",
      "1\t[-0.389,-0.009]\t-0.864\t33.677\n",
      "2\t[0.022,0.199]\t-4.201\t40.221\n",
      "3\t[0.200,0.168]\t-6.867\t30.562\n",
      "4\t[0.364,0.068]\t-7.267\t7.573\n",
      "5\t[0.475,0.031]\t-7.349\t6.891\n",
      "6\t[0.490,0.007]\t-7.352\t0.861\n",
      "7\t[0.490,0.007]\t-7.352\t0.451\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "delta=1e-3\n",
    "ep1=1e-3\n",
    "x = [-1,1]\n",
    "A=np.eye(len(x))\n",
    "fx_prev=funcx(x)\n",
    "print('Initial function value = {0:.3f} '.format(fx_prev))\n",
    "print(' No.\\tx-vector\\tf(x)\\tDeriv ')\n",
    "print('------------------------------------------')\n",
    "for i in range(50):\n",
    "    if i==0:\n",
    "        dire_prev=gradient(x,delta)\n",
    "        si_prev = -dire_prev\n",
    "        alpha,fx_prev = golden(x,si_prev,xi,ep1);\n",
    "        \n",
    "        if la.norm(dire_prev)<ep1:\n",
    "            break\n",
    "        x_c = x +  alpha*si_prev\n",
    "    else:\n",
    "        deltax=x_c-x\n",
    "        dire_c=gradient(x_c,delta)\n",
    "        deltag=dire_c-dire_prev\n",
    "        ter1= np.matmul(np.atleast_2d(deltax).transpose(),np.atleast_2d(deltax) ) /    np.matmul(deltax,deltag.transpose() )\n",
    "        ter2= np.matmul(np.matmul(np.matmul(A, np.atleast_2d(deltag).transpose()), np.atleast_2d(deltag)),A) / np.matmul(np.matmul(np.atleast_2d(deltag),A ), np.atleast_2d(deltag).transpose())\n",
    "        A = A + ter1 - ter2;\n",
    "        si=np.matmul(-A,dire_c.transpose())\n",
    "        si=np.ndarray.flatten(si.transpose())\n",
    "        alpha,fx_curr = golden(x_c[:],si,xi,ep1)\n",
    "        \n",
    "        if abs(fx_curr-fx_prev)<ep1 or la.norm(dire_c)<ep1:\n",
    "            break\n",
    "        fx_prev=fx_curr\n",
    "        dire_prev=dire_c\n",
    "        x=x_c\n",
    "        x_c = x +  alpha*si\n",
    "    print('{0}\\t[{1:.3f},{2:.3f}]\\t{3:.3f}\\t{4:.3f}'.format(i, x[0], x[1],fx_curr,la.norm(dire_c)))\n",
    "print('{0}\\t[{1:.3f},{2:.3f}]\\t{3:.3f}\\t{4:.3f}'.format(i, x[0], x[1],fx_curr,la.norm(dire_c)))\n",
    "print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

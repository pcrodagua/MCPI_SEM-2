{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broyden–Fletcher–Goldfarb–Shanno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 1970, se propúso como alternativa actualizar la fórmula sugerida pro DFP. Para esto Broyden–Fletcher–Goldfarb–Shanno.\n",
    "Crearon un método el cual deriva del anterior método, llegando a obtener un nuevo término llamado _dualidad_ o _complementariedad_. Para discutir este concepto, hay que tener en mente que se realizó una actualización de la aproximación del inverso de la matriz Hessiana, las cuales satisfacen la siguiente ecuación:\n",
    "\n",
    "$$ H_{k + 1} \\triangle g^i = \\triangle x^i,    0 <=i <= k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabe destacar que la aproximación de la Hessiana se da al usar una matriz de variables paramétricas dada por la siguiente ecuación:\n",
    "\n",
    "$$ [A]_{i + j} = [A]_i + \\frac{g\\nabla g^T}{\\nabla g^T\\triangle{x}} + \\frac{\\nabla f(x_i)\\nabla f(x_i)^T}{\\nabla f(x_i)^TS_i} $$\n",
    "\n",
    "Es importante tener en cuenta que mientras que la matriz $[A]$ converge a la inversa de la Hessiana en el método DFP, la matriz $[A]$ converge a la Hessiana en sí mismo en el método BFGS. Esto permite tener menos inicios al método BFGS en comparación del método de DFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo BFGS\n",
    "\n",
    "Paso 01: Inicializar parámetros\n",
    "* Obtener $x_i$, variable de diseño\n",
    "* Establecer los parámetros $ε_1$ y $ε_2$\n",
    "* Inicializar $\\triangle x$ con el fin de calcular el gradiente\n",
    "* Inicializar la matrix $[A]$ a una matriz identidad.\n",
    "\n",
    "Paso 02: Calcular la función: $f(x_i)$ y el gradiente: $\\nabla f(x_i)$\n",
    "* Calcular la dirección de búsqueda: $S_i = \\nabla f(x_i)$\n",
    "* Actualizar el vector de Diseño: $x_{i + 1} = x_i + \\alpha S_i$\n",
    "* Minimizar la función $f(x_{i+1})$ y determinar $\\alpha$ mediante el método de la sección dorada.\n",
    "\n",
    "Paso 03: $\\triangle x$ y $\\nabla g$\n",
    "* $ [A]_{i + j} = [A]_i + \\frac{g\\nabla g^T}{\\nabla g^T\\triangle{x}} + \\frac{\\nabla f(x_i)\\nabla f(x_i)^T}{\\nabla f(x_i)^TS_i}$\n",
    "* $S_i = -[[A]_{i + 1}]^{-1}\\nabla f(x_{i + 1})$\n",
    "* $X_{i + 2} + \\alpha S_{i + 1}$\n",
    "* Minimizar $f(x_{i+2})$ y determinar $\\alpha$ nuevamente.\n",
    "\n",
    "Repetir paso 3 hasta que:\n",
    "* $|f(x_{i + 2}) - f(x_{i + 1})| > ε$ or $||\\nabla f(x_{i + 1})|| > ε$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
